{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladislavlialin/miniconda3/envs/ldm/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "import easyocr\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class CraftOCap:\n",
    "    def __init__(self, use_gpu=None):\n",
    "        if use_gpu is None:\n",
    "            use_gpu = torch.cuda.is_available()\n",
    "\n",
    "        self.ocr = easyocr.Reader([\"en\"], detect_network='craft', gpu=use_gpu)\n",
    "        self.chrf = evaluate.load(\"chrf\", char_order=4)\n",
    "\n",
    "    def compute(self, *, images=None, captions=None, progress_bar=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images: a numpy array of shape (N, H, W, 3)\n",
    "            captions: list of captions\n",
    "        \"\"\"\n",
    "        assert len(images) == len(captions)\n",
    "        ocr_texts = []\n",
    "        for image in tqdm(images, disable=not progress_bar):\n",
    "            ocr_output = self.ocr.readtext(\n",
    "                image=image,\n",
    "                batch_size=64,\n",
    "            )\n",
    "            \n",
    "            full_ocr_text = \"\"\n",
    "            for ocr_item in ocr_output:\n",
    "                ocr_confidence = ocr_item[2]\n",
    "                ocr_text = ocr_item[1].lower()\n",
    "                full_ocr_text += ocr_text + \" \"\n",
    "            \n",
    "            ocr_texts.append(full_ocr_text)\n",
    "        \n",
    "        score = self.chrf.compute(predictions=ocr_texts, references=captions)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladislavlialin/miniconda3/envs/ldm/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "import easyocr\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# fix easyocr version 1.6.2\n",
    "use_gpu = False\n",
    "ocr_system = easyocr.Reader([\"en\"], detect_network='craft', gpu=use_gpu)\n",
    "# chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics.chrf import CHRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 9.01k/9.01k [00:00<00:00, 1.88MB/s]\n"
     ]
    }
   ],
   "source": [
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@inproceedings{popovic-2015-chrf,\\n    title = \"chr{F}: character n-gram {F}-score for automatic {MT} evaluation\",\\n    author = \"Popovi{\\'c}, Maja\",\\n    booktitle = \"Proceedings of the Tenth Workshop on Statistical Machine Translation\",\\n    month = sep,\\n    year = \"2015\",\\n    address = \"Lisbon, Portugal\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/W15-3049\",\\n    doi = \"10.18653/v1/W15-3049\",\\n    pages = \"392--395\",\\n}\\n@inproceedings{popovic-2017-chrf,\\n    title = \"chr{F}++: words helping character n-grams\",\\n    author = \"Popovi{\\'c}, Maja\",\\n    booktitle = \"Proceedings of the Second Conference on Machine Translation\",\\n    month = sep,\\n    year = \"2017\",\\n    address = \"Copenhagen, Denmark\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/W17-4770\",\\n    doi = \"10.18653/v1/W17-4770\",\\n    pages = \"612--618\",\\n}\\n@inproceedings{post-2018-call,\\n    title = \"A Call for Clarity in Reporting {BLEU} Scores\",\\n    author = \"Post, Matt\",\\n    booktitle = \"Proceedings of the Third Conference on Machine Translation: Research Papers\",\\n    month = oct,\\n    year = \"2018\",\\n    address = \"Belgium, Brussels\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/W18-6319\",\\n    pages = \"186--191\",\\n}\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chrF2 = 100.00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrf = CHRF(word_order=0)\n",
    "\n",
    "chrf.sentence_score(hypothesis=\"hello world\", references=[\"hello world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying CHRF to use mutiple hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "def extract_word_ngrams(tokens: List[str], n: int) -> Counter:\n",
    "    \"\"\"Extracts n-grams with order `n` from a list of tokens.\n",
    "    :param tokens: A list of tokens.\n",
    "    :param n: The order of n-grams.\n",
    "    :return: a Counter object with n-grams counts.\n",
    "    \"\"\"\n",
    "    return Counter([' '.join(tokens[i:i + n]) for i in range(len(tokens) - n + 1)])\n",
    "\n",
    "\n",
    "def extract_all_word_ngrams(line: str, min_order: int, max_order: int):\n",
    "    \"\"\"Extracts all ngrams (min_order <= n <= max_order) from a sentence.\n",
    "    :param line: A string sentence.\n",
    "    :param min_order: Minimum n-gram order.\n",
    "    :param max_order: Maximum n-gram order.\n",
    "    :return: a Counter object with n-grams counts and the sequence length.\n",
    "    \"\"\"\n",
    "\n",
    "    ngrams = []\n",
    "    tokens = line.split()\n",
    "\n",
    "    for n in range(min_order, max_order + 1):\n",
    "        for i in range(0, len(tokens) - n + 1):\n",
    "            ngrams.append(tuple(tokens[i: i + n]))\n",
    "\n",
    "    return Counter(ngrams), len(tokens)\n",
    "\n",
    "\n",
    "def extract_all_char_ngrams(\n",
    "        line: str, max_order: int, include_whitespace: bool = False) -> List[Counter]:\n",
    "    \"\"\"Extracts all character n-grams at once for convenience.\n",
    "    :param line: A segment containing a sequence of words.\n",
    "    :param max_order: The maximum order of the n-grams.\n",
    "    :param include_whitespace: If given, will not strip whitespaces from the line.\n",
    "    :return: a list of Counter objects containing ngrams and counts.\n",
    "    \"\"\"\n",
    "\n",
    "    counters = []\n",
    "\n",
    "    if not include_whitespace:\n",
    "        line = ''.join(line.split())\n",
    "\n",
    "    for n in range(1, max_order + 1):\n",
    "        ngrams = Counter([line[i:i + n] for i in range(len(line) - n + 1)])\n",
    "        counters.append(ngrams)\n",
    "\n",
    "    return counters\n",
    "\n",
    "def sum_of_lists(lists):\n",
    "    \"\"\"Aggregates list of numeric lists by summing.\"\"\"\n",
    "    if len(lists) == 1:\n",
    "        return lists[0]\n",
    "\n",
    "    # Preserve datatype\n",
    "    size = len(lists[0])\n",
    "    init_val = type(lists[0][0])(0.0)\n",
    "    total = [init_val] * size\n",
    "    for ll in lists:\n",
    "        for i in range(size):\n",
    "            total[i] += ll[i]\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics.base import Score, Metric\n",
    "\n",
    "class CHRFMultihypScore(Score):\n",
    "    \"\"\"A convenience class to represent chrF scores.\n",
    "    :param score: The chrF (chrF++) score.\n",
    "    :param char_order: The character n-gram order.\n",
    "    :param word_order: The word n-gram order. If equals to 2, the metric is referred to as chrF++.\n",
    "    :param beta: Determine the importance of recall w.r.t precision.\n",
    "    \"\"\"\n",
    "    def __init__(self, score: float, char_order: int, word_order: int, beta: int):\n",
    "        \"\"\"`CHRFScore` initializer.\"\"\"\n",
    "        self.beta = beta\n",
    "        self.char_order = char_order\n",
    "        self.word_order = word_order\n",
    "\n",
    "        # Add + signs to denote chrF+ variant\n",
    "        name = f'chrF{self.beta}' + '+' * self.word_order\n",
    "\n",
    "        super().__init__(name, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CHRFMultihyp(Metric):\n",
    "    \"\"\"Computes the chrF(++) metric given hypotheses and references.\n",
    "    Compared to sacrebleu implementation (which it is based on) it can accept multiple hypotheses, which is requres for *OCap.\n",
    "\n",
    "    :param char_order: Character n-gram order.\n",
    "    :param word_order: Word n-gram order. If equals to 2, the metric is referred to as chrF++.\n",
    "    :param beta: Determine the importance of recall w.r.t precision.\n",
    "    :param lowercase: Enable case-insensitivity.\n",
    "    :param whitespace: If `True`, include whitespaces when extracting character n-grams.\n",
    "    :param eps_smoothing: If `True`, applies epsilon smoothing similar\n",
    "    to reference chrF++.py, NLTK and Moses implementations. Otherwise,\n",
    "    it takes into account effective match order similar to sacreBLEU < 2.0.0.\n",
    "    :param references: A sequence of reference documents with document being\n",
    "    defined as a sequence of reference strings. If given, the reference n-grams\n",
    "    will be pre-computed and cached for faster re-computation across many systems.\n",
    "    \"\"\"\n",
    "\n",
    "    # Maximum character n-gram order to take into account\n",
    "    CHAR_ORDER = 6\n",
    "\n",
    "    # chrF+ additionally takes into account some of the word n-grams\n",
    "    WORD_ORDER = 0\n",
    "\n",
    "    # Defaults to 2 (per http://www.aclweb.org/anthology/W16-2341)\n",
    "    BETA = 2\n",
    "\n",
    "    # Cache string.punctuation for chrF+' punctuation stripper\n",
    "    _PUNCTS = set('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "\n",
    "    # _SIGNATURE_TYPE = CHRFSignature\n",
    "\n",
    "    def __init__(self, char_order: int = CHAR_ORDER,\n",
    "                 word_order: int = WORD_ORDER,\n",
    "                 beta: int = BETA,\n",
    "                 lowercase: bool = False,\n",
    "                 whitespace: bool = False,\n",
    "                 eps_smoothing: bool = False,\n",
    "                 references: Optional[Sequence[Sequence[str]]] = None):\n",
    "        \"\"\"`CHRF` initializer.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.beta = beta\n",
    "        self.char_order = char_order\n",
    "        self.word_order = word_order\n",
    "        self.order = self.char_order + self.word_order\n",
    "        self.lowercase = lowercase\n",
    "        self.whitespace = whitespace\n",
    "        self.eps_smoothing = eps_smoothing\n",
    "\n",
    "        # if references is not None:\n",
    "        #     # Pre-compute reference ngrams\n",
    "        #     self._ref_cache = self._cache_references(references)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_match_statistics(hyp_ngrams_list: List[Counter], ref_ngrams: Counter) -> List[int]:\n",
    "        \"\"\"Computes the match statistics between hypothesis and reference n-grams.\n",
    "        :param hyp_ngrams: A `Counter` holding hypothesis n-grams.\n",
    "        :param ref_ngrams: A `Counter` holding reference n-grams.\n",
    "        :return: A list of three numbers denoting hypothesis n-gram count,\n",
    "            reference n-gram count and the intersection count.\n",
    "        \"\"\"\n",
    "        # Counter's internal intersection is not that fast, count manually\n",
    "        match_count, hyp_count = 0, 0\n",
    "        for hyp_ngrams in hyp_ngrams_list:\n",
    "            for ng, count in hyp_ngrams.items():\n",
    "                hyp_count += count\n",
    "                if ng in ref_ngrams:\n",
    "                    match_count += min(count, ref_ngrams[ng])\n",
    "\n",
    "        return [\n",
    "            # Don't count hits if no reference exists for that n-gram\n",
    "            hyp_count if ref_ngrams else 0,\n",
    "            sum(ref_ngrams.values()),\n",
    "            match_count,\n",
    "        ]\n",
    "\n",
    "    def _remove_punctuation(self, sent: str) -> List[str]:\n",
    "        \"\"\"Separates out punctuations from beginning and end of words for chrF.\n",
    "        Adapted from https://github.com/m-popovic/chrF\n",
    "        :param sent: A string.\n",
    "        :return: A list of words.\n",
    "        \"\"\"\n",
    "        tokenized = []\n",
    "        for w in sent.split():\n",
    "            if len(w) == 1:\n",
    "                tokenized.append(w)\n",
    "            else:\n",
    "                # NOTE: This splits '(hi)' to '(hi' and ')' (issue #124)\n",
    "                if w[-1] in self._PUNCTS:\n",
    "                    tokenized += [w[:-1], w[-1]]\n",
    "                elif w[0] in self._PUNCTS:\n",
    "                    tokenized += [w[0], w[1:]]\n",
    "                else:\n",
    "                    tokenized.append(w)\n",
    "        return tokenized\n",
    "\n",
    "    def _preprocess_segment(self, sent: str) -> str:\n",
    "        \"\"\"Given a sentence, apply optional lowercasing.\n",
    "        :param sent: The input sentence string.\n",
    "        :return: The pre-processed output string.\n",
    "        \"\"\"\n",
    "        return sent.lower() if self.lowercase else sent\n",
    "\n",
    "    def _compute_f_score(self, statistics: List[int]) -> float:\n",
    "        \"\"\"Compute the chrF score given the n-gram match statistics.\n",
    "        :param statistics: A flattened list of 3 * (`char_order` + `word_order`)\n",
    "            elements giving the [hyp, ref, match] counts for each order.\n",
    "        :return: The final f_beta score between [0, 100].\n",
    "        \"\"\"\n",
    "        eps = 1e-16\n",
    "        score = 0.0\n",
    "        effective_order = 0\n",
    "        factor = self.beta ** 2\n",
    "        avg_prec, avg_rec = 0.0, 0.0\n",
    "\n",
    "        for i in range(self.order):\n",
    "            n_hyp, n_ref, n_match = statistics[3 * i: 3 * i + 3]\n",
    "\n",
    "            # chrF++.py style EPS smoothing (also used by Moses and NLTK)\n",
    "            prec = n_match / n_hyp if n_hyp > 0 else eps\n",
    "            rec = n_match / n_ref if n_ref > 0 else eps\n",
    "\n",
    "            denom = factor * prec + rec\n",
    "            score += ((1 + factor) * prec * rec / denom) if denom > 0 else eps\n",
    "\n",
    "            # sacreBLEU <2.0.0 style effective order smoothing\n",
    "            if n_hyp > 0 and n_ref > 0:\n",
    "                avg_prec += prec\n",
    "                avg_rec += rec\n",
    "                effective_order += 1\n",
    "\n",
    "        if self.eps_smoothing:\n",
    "            return 100 * score / self.order\n",
    "\n",
    "        if effective_order == 0:\n",
    "            avg_prec = avg_rec = 0.0\n",
    "        else:\n",
    "            avg_prec /= effective_order\n",
    "            avg_rec /= effective_order\n",
    "\n",
    "        if avg_prec + avg_rec:\n",
    "            score = (1 + factor) * avg_prec * avg_rec\n",
    "            score /= ((factor * avg_prec) + avg_rec)\n",
    "            return 100 * score\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def _compute_score_from_stats(self, stats: List[int]) -> CHRFMultihypScore:\n",
    "        \"\"\"Computes the final score from already aggregated statistics.\n",
    "        :param stats: A list or numpy array of segment-level statistics.\n",
    "        :return: A `CHRFScore` object.\n",
    "        \"\"\"\n",
    "        return CHRFMultihypScore(\n",
    "            self._compute_f_score(stats),\n",
    "            self.char_order,\n",
    "            self.word_order,\n",
    "            self.beta,\n",
    "        )\n",
    "\n",
    "    def _aggregate_and_compute(self, stats: List[List[int]]) -> CHRFMultihypScore:\n",
    "        \"\"\"Computes the final score given the pre-computed corpus statistics.\n",
    "        :param stats: A list of segment-level statistics\n",
    "        :return: A `CHRFScore` object.\n",
    "        \"\"\"\n",
    "        return self._compute_score_from_stats(sum_of_lists(stats))\n",
    "\n",
    "    def _extract_reference_info(self, refs: Sequence[str]) -> Dict[str, List[List[Counter]]]:\n",
    "        \"\"\"Given a list of reference segments, extract the character and word n-grams.\n",
    "        :param refs: A sequence of reference segments.\n",
    "        :return: A list where each element contains n-grams per reference segment.\n",
    "        \"\"\"\n",
    "        ngrams = []\n",
    "\n",
    "        for ref in refs:\n",
    "            # extract character n-grams\n",
    "            stats = extract_all_char_ngrams(ref, self.char_order, self.whitespace)\n",
    "\n",
    "            # Check chrF+ mode\n",
    "            if self.word_order > 0:\n",
    "                ref_words = self._remove_punctuation(ref)\n",
    "\n",
    "                for n in range(self.word_order):\n",
    "                    stats.append(extract_word_ngrams(ref_words, n + 1))\n",
    "\n",
    "            ngrams.append(stats)\n",
    "\n",
    "        return {'ref_ngrams': ngrams}\n",
    "\n",
    "    def _compute_segment_statistics(\n",
    "            self, hypothesis: List[str], ref_kwargs: Dict) -> List[int]:\n",
    "        \"\"\"Given a (pre-processed) hypothesis sentence and already computed\n",
    "        reference n-grams, returns the best match statistics across the\n",
    "        references.\n",
    "        :param hypothesis: Hypothesis sentence.\n",
    "        :param ref_kwargs: A dictionary with key `ref_ngrams` which is a list\n",
    "        where each sublist contains n-gram counters for a particular reference sentence.\n",
    "        :return: A list of integers where each triplet denotes [hyp, ref, match]\n",
    "        statistics.\n",
    "        \"\"\"\n",
    "        best_stats = []\n",
    "        best_f_score = -1.0\n",
    "\n",
    "        # extract character n-grams\n",
    "        # all_hyp_ngrams = [\n",
    "        #     extract_all_char_ngrams(h, self.char_order, self.whitespace)\n",
    "        #     for h in hypothesis\n",
    "        # ]\n",
    "\n",
    "        all_hyp_ngrams_list = []\n",
    "        for hyp in hypothesis:\n",
    "            all_hyp_ngrams = extract_all_char_ngrams(\n",
    "                hypothesis, self.char_order, self.whitespace)\n",
    "\n",
    "            # Check chrF+ mode to see if we'll add word n-grams as well\n",
    "            if self.word_order > 0:\n",
    "                # Primitive tokenization: separate out punctuations\n",
    "                hwords = self._remove_punctuation(hypothesis)\n",
    "                _range = range(1, self.word_order + 1)\n",
    "                all_hyp_ngrams.extend([extract_word_ngrams(hwords, n) for n in _range])\n",
    "            \n",
    "            all_hyp_ngrams_list.append(all_hyp_ngrams)\n",
    "\n",
    "        # Iterate over multiple references, pick the one with best F score\n",
    "        for _ref_ngrams in ref_kwargs['ref_ngrams']:\n",
    "            stats = []\n",
    "            # Traverse all orders\n",
    "            for h, r in zip(all_hyp_ngrams, _ref_ngrams):\n",
    "                stats.extend(self._get_match_statistics(h, r))\n",
    "            f_score = self._compute_f_score(stats)\n",
    "\n",
    "            if f_score > best_f_score:\n",
    "                best_f_score = f_score\n",
    "                best_stats = stats\n",
    "\n",
    "        return best_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "ldm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "432ba331b8c3b887a90b9e54f38d7b4ed998c99602a41d3d14be617c514e9c8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
